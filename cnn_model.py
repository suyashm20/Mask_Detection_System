# -*- coding: utf-8 -*-
"""cnn_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sp80MfS3sOJHeZAJC-nEKurN6Ei1GJ5Q
"""

import os
import tensorflow as tf
from keras.preprocessing import image
from keras.preprocessing.image import array_to_img
import matplotlib.pyplot as plt 
import numpy as np
from keras.utils.np_utils import to_categorical
import random,shutil
from keras.models import Sequential
from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization
from keras.models import load_model



# train_ds = tf.keras.preprocessing.image_dataset_from_directory(
#     "dataset",
#     validation_split=0.2,
#     subset="training",
#     seed=1337
   
# )
# val_ds = tf.keras.preprocessing.image_dataset_from_directory(
#     "dataset",
#     validation_split=0.2,
#     subset="validation",
#     seed=1337
    
# )


def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' , save_to_dir = 'vis_train' , save_format = "jpeg" ):

    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size ,
                                   save_to_dir = 'vis_train' , save_format = "jpeg")

BS= 10
TS=(24,24)



!mkdir -p vis_train
!rm -r vis_train

train_batch= generator('dataset/train',shuffle=True, batch_size=BS,target_size=TS , save_to_dir = 'vis_train' , save_format = "jpeg")
valid_batch= generator('dataset/test',shuffle=True, batch_size=BS,target_size=TS)
SPE= len(train_batch.classes)//BS
VS = len(valid_batch.classes)//BS
print(SPE,VS)



model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),
    MaxPooling2D(pool_size=(1,1)),
    Conv2D(32,(3,3),activation='relu'),
    MaxPooling2D(pool_size=(1,1)),
#32 convolution filters used each of size 3x3
#again
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(1,1)),

#64 convolution filters used each of size 3x3
#choose the best features via pooling
    
#randomly turn neurons on and off to improve convergence
    Dropout(0.25),
#flatten since too many dimensions, we only want a classification output
    Flatten(),
#fully connected to get all relevant data
    Dense(128, activation='relu'),
#one more dropout for convergence' sake :) 
   
    Dropout(0.5),
#output a softmax to squash the matrix into output probabilities
    Dense(2, activation='softmax')
])

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)



!mkdir -p models

model.save('models/cnn_150.h5', overwrite=True)

model.summary()

"""##### predict class ######"""

img = image.load_img(
    "dataset/test/1_masked/masked45.jpg", target_size=TS , color_mode="grayscale"
)
 
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, 0)  # Create batch axis

predictions = model.predict(img_array)


predictions
plt.imshow(img)

!unrar x dataset.rar  ### unrar

"""Check labels of training images"""

x,y = train_batch[0]
q = x[8]
#q = q.reshape(24,24,-1)
print(q.shape)
plt.imshow(q)
y[8]
